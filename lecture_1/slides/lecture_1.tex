\documentclass[aspectratio=169]{beamer}
\usetheme{Madrid}
\usecolortheme{default}

\title{LLMs, Agents, and MCP}
\subtitle{Part 1: Large Language Models (LLMs) - Starting from Zero}
\author{University of Chicago}
\date{\today}

\begin{document}

\frame{\titlepage}

\section{Part 1: Large Language Models (LLMs)}

\begin{frame}{What is an LLM?}
\begin{itemize}
    \item A \textbf{Large Language Model (LLM)} is an artificial intelligence system trained on massive amounts of text data (often trillions of words)
    \item These models learn patterns in language and can:
    \begin{itemize}
        \item Generate human-like text
        \item Answer questions
        \item Translate languages
        \item Summarize documents
        \item Write code
        \item And much more
    \end{itemize}
    \item Think of an LLM as a very sophisticated autocomplete system that has read a significant portion of the internet
\end{itemize}
\end{frame}

\begin{frame}{Foundation Models}
\begin{itemize}
    \item A \textbf{foundation model} is a large-scale machine learning model trained on broad data (generally using self-supervision at scale) that can be adapted to a wide range of downstream tasks
    \item \textbf{Key characteristics:}
    \begin{itemize}
        \item Broad training: Trained on diverse, large-scale datasets
        \item General-purpose: Can be adapted to many different tasks
        \item Transfer learning: Knowledge learned from training can be applied to new tasks
        \item Base for specialization: Can be fine-tuned or used as-is for specific applications
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Foundation Models vs LLMs}
\begin{itemize}
    \item \textbf{Foundation Model} is the broader categoryâ€”it includes models for vision, audio, code, etc.
    \item \textbf{LLM (Large Language Model)} is a type of foundation model focused specifically on language
    \item \textbf{Examples of foundation models:}
    \begin{itemize}
        \item \textbf{Language}: GPT-4, Claude, Llama (these are LLMs)
        \item \textbf{Vision}: CLIP, DALL-E
        \item \textbf{Code}: Codex, CodeLlama
        \item \textbf{Multimodal}: GPT-4V (vision + language), Gemini (multimodal)
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Key Terminology}
\begin{itemize}
    \item \textbf{Foundation Model}: A large-scale model trained on broad data that can be adapted to many tasks
    \item \textbf{LLM (Large Language Model)}: A type of foundation model specifically designed for language tasks
    \item \textbf{Token}: The basic unit of text that an LLM processes (word, part of word, or punctuation)
    \item \textbf{Prompt}: The input text you give to an LLM
    \item \textbf{Completion/Response}: The output text generated by the LLM
    \item \textbf{Context Window}: The maximum number of tokens an LLM can process in a single conversation
\end{itemize}
\end{frame}

\begin{frame}{Key Terminology (continued)}
\begin{itemize}
    \item \textbf{Temperature}: A parameter that controls randomness (Lower = more deterministic, Higher = more creative)
    \item \textbf{Fine-tuning}: Training an LLM on specific data to improve performance on particular tasks
    \item \textbf{Inference}: The process of generating text from an LLM (as opposed to training)
\end{itemize}
\end{frame}

\begin{frame}{Example LLM Models: Commercial}
\begin{itemize}
    \item \textbf{GPT-4} (OpenAI)
    \begin{itemize}
        \item One of the most capable models
        \item Available via OpenAI API
        \item Powers ChatGPT Plus
    \end{itemize}
    \item \textbf{Claude 3.5 Sonnet} (Anthropic)
    \begin{itemize}
        \item Strong reasoning and coding capabilities
        \item Available via Anthropic API
    \end{itemize}
    \item \textbf{Gemini Pro} (Google)
    \begin{itemize}
        \item Google's flagship model
        \item Available via Google AI Studio
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Example LLM Models: Open Source}
\begin{itemize}
    \item \textbf{Hugging Face} is a platform hosting thousands of open-source models
    \item Popular models include:
    \begin{itemize}
        \item \textbf{Llama 3} (Meta)
        \item \textbf{Mistral} (Mistral AI)
        \item \textbf{Phi} (Microsoft)
        \item \textbf{Gemma} (Google)
    \end{itemize}
    \item You can use these models via:
    \begin{itemize}
        \item Hugging Face Transformers library (Python)
        \item Hugging Face Inference API
        \item Local deployment
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Model Aggregators}
\begin{itemize}
    \item \textbf{Open Router} provides access to many models through a single API
    \begin{itemize}
        \item Unified API for 100+ models
        \item Compare models side-by-side
        \item Pay-per-use pricing
        \item Easy to switch between models
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{LLM Limitations}
While LLMs are powerful, they have important limitations:
\begin{enumerate}
    \item \textbf{Knowledge Cutoff}: They only know information from their training data up to a certain date
    \item \textbf{Hallucination}: They can generate plausible-sounding but incorrect information
    \item \textbf{No Real-World Actions}: They can't directly interact with external systems (databases, APIs, file systems)
    \item \textbf{Context Limits}: They have maximum context window sizes
    \item \textbf{Static Knowledge}: They can't learn new information after training without fine-tuning or retrieval
\end{enumerate}
\end{frame}

\section{Part 2: AI Agents}

\begin{frame}{What is an AI Agent?}
\begin{itemize}
    \item An \textbf{AI Agent} is an LLM that can use \textbf{tools} to interact with the outside world
    \item While a basic LLM can only generate text based on its training data, an agent can:
    \begin{itemize}
        \item Query databases
        \item Call APIs
        \item Read files
        \item Execute code
        \item Search the web
        \item Perform actions in real-time
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{LLM vs Agent: Key Differences}
\begin{table}
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Aspect} & \textbf{LLM} & \textbf{Agent} \\
\hline
Capabilities & Text generation only & Text + tool usage \\
\hline
Knowledge & Training data only & Training data + real-time data \\
\hline
Actions & None & Can perform actions via tools \\
\hline
Interactivity & One-shot responses & Can loop and iterate \\
\hline
\end{tabular}
\end{table}
\end{frame}

\begin{frame}{The Agent Loop}
\begin{center}
\Large
Observe $\rightarrow$ Think $\rightarrow$ Act $\rightarrow$ Observe $\rightarrow$ \ldots
\end{center}
\vspace{1cm}
\begin{enumerate}
    \item \textbf{Observe}: Receive input (user query, tool results, system state)
    \item \textbf{Think}: Process information and decide what to do next
    \item \textbf{Act}: Execute actions (call tools, generate responses)
    \item \textbf{Observe}: See the results and continue the loop
\end{enumerate}
\end{frame}

\begin{frame}{Example Agent Systems}
\begin{itemize}
    \item \textbf{LangChain Agents}
    \begin{itemize}
        \item Framework for building LLM applications
        \item Supports multiple LLM providers
        \item Tool integration and agent orchestration
    \end{itemize}
    \item \textbf{Claude with MCP} (Model Context Protocol)
    \begin{itemize}
        \item Claude Desktop can connect to MCP servers
        \item Access custom tools and data sources
    \end{itemize}
    \item \textbf{ChatGPT with Plugins/Code Interpreter}
    \item \textbf{Cursor AI}
\end{itemize}
\end{frame}

\section{Part 3: Tools}

\begin{frame}{What is a Tool?}
\begin{itemize}
    \item A \textbf{tool} is a function that an AI agent can call to interact with external systems
    \item Tools bridge the gap between the LLM's text generation capabilities and real-world actions
    \item Every tool has:
    \begin{enumerate}
        \item \textbf{Name}: A unique identifier (e.g., \texttt{get\_player\_list})
        \item \textbf{Description}: What the tool does and when to use it
        \item \textbf{Input Schema}: Parameters the tool accepts (JSON Schema format)
        \item \textbf{Implementation}: The actual code that executes when called
    \end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}{Common Tool Categories}
\begin{itemize}
    \item \textbf{Database Tools}: Query databases, insert/update/delete records
    \item \textbf{API Tools}: Call REST APIs, interact with web services
    \item \textbf{File System Tools}: Read/write files, list directories
    \item \textbf{Code Execution Tools}: Run Python code, execute shell commands
    \item \textbf{Web Tools}: Search the web, scrape websites
\end{itemize}
\end{frame}

\section{Part 4: Model Context Protocol (MCP)}

\begin{frame}{What is MCP?}
\begin{itemize}
    \item The \textbf{Model Context Protocol (MCP)} is an open protocol created by Anthropic
    \item Enables AI assistants to securely connect to external tools and data sources
    \item Provides a standardized way for AI assistants to discover and use capabilities from external systems
\end{itemize}
\end{frame}

\begin{frame}{Why MCP?}
\begin{itemize}
    \item Before MCP, each AI assistant had its own way of connecting to external tools:
    \begin{itemize}
        \item ChatGPT had plugins
        \item Claude had custom integrations
        \item Each system was proprietary
    \end{itemize}
    \item MCP provides:
    \begin{itemize}
        \item \textbf{Standardization}: One protocol works across multiple AI assistants
        \item \textbf{Security}: Secure, controlled access to tools
        \item \textbf{Discoverability}: AI assistants can discover available tools automatically
        \item \textbf{Composability}: Tools can be combined and chained together
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{MCP Architecture}
\begin{center}
\Large
AI Assistant (MCP Client) \\
$\downarrow$ \\
MCP Protocol \\
$\downarrow$ \\
MCP Server \\
$\downarrow$ \\
Your Application (Flask API, Database, File System)
\end{center}
\end{frame}

\begin{frame}{Key MCP Components}
\begin{enumerate}
    \item \textbf{MCP Server}: Exposes capabilities (tools, resources, prompts) to AI assistants
    \item \textbf{MCP Client}: AI assistant that connects to servers (Claude Desktop, Cursor, etc.)
    \item \textbf{Tools}: Functions that an AI can call to interact with external systems
    \item \textbf{Resources}: Data sources that an AI can read (files, database tables, API endpoints)
    \item \textbf{Prompts}: Pre-defined prompt templates for common tasks
\end{enumerate}
\end{frame}

\begin{frame}{How MCP Works}
\begin{enumerate}
    \item User asks: "Get me all players"
    \item MCP Client analyzes query and selects appropriate tool
    \item Client calls tool: \texttt{get\_player\_list()}
    \item MCP Server makes HTTP request to Flask API
    \item API returns player data
    \item Server returns tool result to client
    \item Client incorporates result into response
    \item User receives: "Here are all the players: \ldots"
\end{enumerate}
\end{frame}

\begin{frame}{Why not a REST API?}
\begin{itemize}
    \item MCP uses \textbf{Server-Sent Events (SSE)} for real-time communication
    \item \textbf{REST}: One request $\rightarrow$ wait $\rightarrow$ one response $\rightarrow$ connection closes
    \item \textbf{MCP/SSE}: Long-lived connection $\rightarrow$ multiple messages $\rightarrow$ streaming updates
    \item This enables:
    \begin{itemize}
        \item Real-time feedback during tool execution
        \item Streaming responses for long operations
        \item Continuous communication between client and server
    \end{itemize}
\end{itemize}
\end{frame}

\section{Part 5: Claude Skills}

\begin{frame}{What are Claude Skills?}
\begin{itemize}
    \item \textbf{Claude Skills} (also called "Actions" or "Tool Use") is Claude's built-in capability to use tools
    \item When you give Claude access to tools, it can:
    \begin{itemize}
        \item Automatically decide when to use tools
        \item Call multiple tools in sequence
        \item Combine tool results into coherent responses
    \end{itemize}
    \item Claude Skills work with:
    \begin{itemize}
        \item MCP servers (via Claude Desktop)
        \item Custom API integrations
        \item Function calling (via Anthropic API)
    \end{itemize}
\end{itemize}
\end{frame}

\section{Part 6: How Everything Works Together}

\begin{frame}{Complete System Architecture}
\begin{center}
\Large
User Interface \\
$\downarrow$ \\
AI Assistant Layer (Claude Desktop) \\
$\downarrow$ \\
MCP Protocol Layer \\
$\downarrow$ \\
MCP Server Layer \\
$\downarrow$ \\
Application Layer (Flask API, Database, File System)
\end{center}
\end{frame}

\begin{frame}{Example: Complete Interaction Flow}
\textbf{Scenario}: User asks "What colleges do players from Washington come from?"
\begin{enumerate}
    \item Claude analyzes query, identifies need for player data
    \item Selects \texttt{get\_players} tool
    \item Calls \texttt{get\_players(team="WAS")}
    \item MCP Server makes GET request to Flask API
    \item API queries database
    \item Returns player records
    \item Claude processes data, extracts unique colleges
    \item Returns formatted response to user
\end{enumerate}
\end{frame}

\begin{frame}{Summary}
\begin{itemize}
    \item \textbf{LLMs} are powerful text generation systems trained on massive datasets
    \item \textbf{AI Agents} extend LLMs with tool-using capabilities
    \item \textbf{Tools} bridge the gap between LLMs and real-world systems
    \item \textbf{MCP} provides a standardized protocol for connecting AI assistants to external tools
    \item Together, these technologies enable AI systems that can interact with the real world
\end{itemize}
\end{frame}

\begin{frame}{Questions?}
\begin{center}
\Large
Thank you!
\end{center}
\end{frame}

\end{document}

