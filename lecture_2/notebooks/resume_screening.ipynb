{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Screening with LLMs\n",
    "\n",
    "**Goal**: Demonstrate structured outputs with LLMs for resume analysis\n",
    "\n",
    "## What You'll Learn\n",
    "1. Load and view resume data\n",
    "2. Use structured outputs to extract information from resumes\n",
    "3. Build reusable functions with clear inputs/outputs\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "OPENROUTER_API_KEY = \"\"  # Paste your key here\n",
    "\n",
    "if not OPENROUTER_API_KEY or OPENROUTER_API_KEY.strip() == \"\":\n",
    "    raise RuntimeError(\n",
    "        \"⚠️  Please set OPENROUTER_API_KEY above before running this notebook.\\n\"\n",
    "        \"Get your key from: https://openrouter.ai/keys\"\n",
    "    )\n",
    "\n",
    "print(\"✓ API key configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import httpx\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "print(\"✓ Imports loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading Resume Data\n",
    "\n",
    "First, we need a function to load our resume data from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resumes(csv_path: str) -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Load all resumes from CSV into a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to the resumes CSV file\n",
    "    \n",
    "    Returns:\n",
    "        Dict mapping resume ID to resume data (ID, Resume_str, Category)\n",
    "    \"\"\"\n",
    "    resumes = {}\n",
    "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            resumes[row['ID']] = {\n",
    "                'ID': row['ID'],\n",
    "                'Resume_str': row['Resume_str'],\n",
    "                'Category': row['Category']\n",
    "            }\n",
    "    return resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all resumes\n",
    "resumes = load_resumes('../data/resumes_final.csv')\n",
    "\n",
    "print(f\"Loaded {len(resumes)} resumes\")\n",
    "print(f\"\\nSample resume IDs:\")\n",
    "for resume_id in list(resumes.keys())[:5]:\n",
    "    print(f\"  {resume_id} - {resumes[resume_id]['Category']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a single resume\n",
    "sample_id = list(resumes.keys())[0]\n",
    "sample_resume = resumes[sample_id]\n",
    "\n",
    "print(f\"Resume ID: {sample_resume['ID']}\")\n",
    "print(f\"Category: {sample_resume['Category']}\")\n",
    "print(f\"\\nResume text (first 800 characters):\")\n",
    "print(\"=\"*70)\n",
    "print(sample_resume['Resume_str'][:800])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Structured Output with LLMs\n",
    "\n",
    "Now we'll create a reusable function that takes:\n",
    "1. A prompt\n",
    "2. A resume\n",
    "3. A structured output schema\n",
    "\n",
    "And returns the structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_resume_with_structure(\n",
    "    api_key: str,\n",
    "    prompt: str,\n",
    "    resume_text: str,\n",
    "    output_schema: str,\n",
    "    model: str = \"anthropic/claude-3.5-sonnet\",\n",
    "    temperature: float = 0.3\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze a resume using an LLM with structured output.\n",
    "    \n",
    "    Args:\n",
    "        api_key: OpenRouter API key\n",
    "        prompt: The instruction for what to analyze\n",
    "        resume_text: The resume text to analyze\n",
    "        output_schema: JSON schema description for the output format\n",
    "        model: Model to use (default: Claude 3.5 Sonnet)\n",
    "        temperature: Sampling temperature (default: 0.3 for consistency)\n",
    "    \n",
    "    Returns:\n",
    "        Dict with 'result' (parsed JSON) and 'error' (if any)\n",
    "    \"\"\"\n",
    "    # Build the full prompt\n",
    "    full_prompt = f\"\"\"{prompt}\n",
    "\n",
    "Resume:\n",
    "{resume_text[:3000]}\n",
    "\n",
    "Return a JSON object with this structure:\n",
    "{output_schema}\n",
    "\n",
    "Return ONLY valid JSON, no additional text.\"\"\"\n",
    "    \n",
    "    # Make API call\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": full_prompt}],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": 1500,\n",
    "        \"response_format\": {\"type\": \"json_object\"}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with httpx.Client(timeout=60) as client:\n",
    "            resp = client.post(url, headers=headers, json=payload)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            \n",
    "            content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "            result = json.loads(content)\n",
    "            \n",
    "            return {\n",
    "                \"result\": result,\n",
    "                \"error\": None,\n",
    "                \"usage\": data.get(\"usage\", {})\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"result\": None,\n",
    "            \"error\": str(e),\n",
    "            \"usage\": {}\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Extract Technical Skills\n",
    "\n",
    "Let's use our function to extract technical skills from a resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what we want to extract\n",
    "prompt = \"Extract the technical skills, programming languages, frameworks, and technologies from this resume.\"\n",
    "\n",
    "# Define the output structure\n",
    "output_schema = \"\"\"\n",
    "{\n",
    "  \"programming_languages\": [\"list of languages\"],\n",
    "  \"frameworks_libraries\": [\"list of frameworks\"],\n",
    "  \"databases\": [\"list of databases\"],\n",
    "  \"cloud_platforms\": [\"list of cloud platforms\"],\n",
    "  \"tools\": [\"list of development tools\"]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Analyze the resume\n",
    "result = analyze_resume_with_structure(\n",
    "    OPENROUTER_API_KEY,\n",
    "    prompt,\n",
    "    sample_resume['Resume_str'],\n",
    "    output_schema\n",
    ")\n",
    "\n",
    "if result['error']:\n",
    "    print(f\"❌ Error: {result['error']}\")\n",
    "else:\n",
    "    print(\"✓ Skills extracted successfully\\n\")\n",
    "    print(json.dumps(result['result'], indent=2))\n",
    "    print(f\"\\nTokens used: {result['usage'].get('total_tokens', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Assess Years of Experience\n",
    "\n",
    "Let's extract experience level information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different prompt and structure\n",
    "prompt = \"Analyze this resume and estimate the candidate's experience level and key qualifications.\"\n",
    "\n",
    "output_schema = \"\"\"\n",
    "{\n",
    "  \"estimated_years_experience\": <number>,\n",
    "  \"experience_level\": \"<entry|junior|mid|senior|principal>\",\n",
    "  \"job_titles\": [\"list of job titles held\"],\n",
    "  \"education\": \"highest degree or education\",\n",
    "  \"key_strengths\": [\"list of 3-5 key strengths\"]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = analyze_resume_with_structure(\n",
    "    OPENROUTER_API_KEY,\n",
    "    prompt,\n",
    "    sample_resume['Resume_str'],\n",
    "    output_schema\n",
    ")\n",
    "\n",
    "if result['error']:\n",
    "    print(f\"❌ Error: {result['error']}\")\n",
    "else:\n",
    "    print(\"✓ Experience assessed successfully\\n\")\n",
    "    print(json.dumps(result['result'], indent=2))\n",
    "    print(f\"\\nTokens used: {result['usage'].get('total_tokens', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Match to Job Requirements\n",
    "\n",
    "Now let's compare a resume against a job requisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a job requisition\n",
    "with open('../data/job_req_senior.md', 'r') as f:\n",
    "    job_req = f.read()\n",
    "\n",
    "print(\"Job Requisition (first 300 characters):\")\n",
    "print(\"=\"*70)\n",
    "print(job_req[:300])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match resume to job\n",
    "prompt = f\"\"\"Compare this resume against the job requirements below and assess the candidate's fit.\n",
    "\n",
    "Job Requirements:\n",
    "{job_req[:2000]}\"\"\"\n",
    "\n",
    "output_schema = \"\"\"\n",
    "{\n",
    "  \"fit_score\": <number 0-100>,\n",
    "  \"recommendation\": \"<STRONG_FIT|GOOD_FIT|MODERATE_FIT|WEAK_FIT|POOR_FIT>\",\n",
    "  \"matching_qualifications\": [\"list of requirements the candidate meets\"],\n",
    "  \"missing_qualifications\": [\"list of requirements the candidate lacks\"],\n",
    "  \"reasoning\": \"<2-3 sentence explanation of the fit score>\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = analyze_resume_with_structure(\n",
    "    OPENROUTER_API_KEY,\n",
    "    prompt,\n",
    "    sample_resume['Resume_str'],\n",
    "    output_schema\n",
    ")\n",
    "\n",
    "if result['error']:\n",
    "    print(f\"❌ Error: {result['error']}\")\n",
    "else:\n",
    "    print(\"✓ Match assessment complete\\n\")\n",
    "    match_data = result['result']\n",
    "    print(f\"Fit Score: {match_data['fit_score']}/100\")\n",
    "    print(f\"Recommendation: {match_data['recommendation']}\")\n",
    "    print(f\"\\nReasoning: {match_data['reasoning']}\")\n",
    "    print(f\"\\nMatching Qualifications ({len(match_data['matching_qualifications'])}):\")\n",
    "    for qual in match_data['matching_qualifications'][:5]:\n",
    "        print(f\"  ✓ {qual}\")\n",
    "    print(f\"\\nMissing Qualifications ({len(match_data['missing_qualifications'])}):\")\n",
    "    for qual in match_data['missing_qualifications'][:5]:\n",
    "        print(f\"  ✗ {qual}\")\n",
    "    print(f\"\\nTokens used: {result['usage'].get('total_tokens', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Simple data loading**: One function returns all resumes as a dictionary\n",
    "2. **Reusable structured output function**: Same function works for different analysis tasks\n",
    "3. **Flexibility**: Change the prompt and output schema to extract different information\n",
    "4. **Clear inputs/outputs**: Each function has a single, well-defined purpose\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Try experimenting with:\n",
    "- Different prompts and output schemas\n",
    "- Analyzing multiple resumes in a loop\n",
    "- Comparing resumes against different job requirements\n",
    "- Extracting other information (soft skills, certifications, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
