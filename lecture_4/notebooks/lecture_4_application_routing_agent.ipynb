{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4 ‚Äî Application Routing Agent\n",
    "\n",
    "**Goal**: Build a simple agentic system that routes job applications through multiple stages\n",
    "\n",
    "## The Agent Loop\n",
    "```\n",
    "while not done:\n",
    "    observe(candidate_features, tool_results)\n",
    "    decide_action()  # LLM chooses which tool to call\n",
    "    execute_tool()\n",
    "    log_result()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from agent_utils import (\n",
    "    structured_llm_call, \n",
    "    load_job_requirements,\n",
    "    TOOL_REGISTRY\n",
    ")\n",
    "\n",
    "# Load resume utilities from lecture 3\n",
    "sys.path.insert(0, str(Path.cwd() / '../lecture_3/notebooks'))\n",
    "from resume_utils import load_resumes\n",
    "\n",
    "random.seed(111)\n",
    "\n",
    "# Configuration\n",
    "OPENROUTER_API_KEY = \"\"  # Paste your key here\n",
    "\n",
    "if not OPENROUTER_API_KEY or OPENROUTER_API_KEY.strip() == \"\":\n",
    "    raise RuntimeError(\n",
    "        \"‚ö†Ô∏è  Please set OPENROUTER_API_KEY above before running this notebook.\\n\"\n",
    "        \"Get your key from: https://openrouter.ai/keys\"\n",
    "    )\n",
    "\n",
    "print(\"‚úì Imports loaded\")\n",
    "print(\"‚úì API key configured\")\n",
    "print(f\"\\nüì¶ Available tools: {len(TOOL_REGISTRY)}\")\n",
    "print(\"   Tools:\", \", \".join(TOOL_REGISTRY.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We'll use the same resumes and job requirements from Lecture 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load resumes and job requirements\n",
    "resumes = load_resumes('../data/resumes_final.csv')\n",
    "job_req = load_job_requirements('../data/job_req_senior.md')\n",
    "\n",
    "print(f\"Loaded {len(resumes)} resumes\")\n",
    "\n",
    "# Sample 3 candidates for demonstration\n",
    "resume_list = list(resumes.values())\n",
    "resume_samples = random.sample(resume_list, 3)\n",
    "\n",
    "print(f\"Selected {len(resume_samples)} candidates for routing\")\n",
    "print(\"\\nCandidate IDs:\", [r['ID'] for r in resume_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Extract Features (From Lecture 3)\n",
    "\n",
    "Before routing, we need to extract key features from each resume.\n",
    "This uses the decomposition technique from Lecture 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction prompt (reusing Lecture 3 concepts)\n",
    "feature_extraction_prompt = \"\"\"\n",
    "Extract key hiring features from this resume.\n",
    "\n",
    "You MUST cite exact quotes from the resume for years of experience.\n",
    "\"\"\"\n",
    "\n",
    "feature_schema = {\n",
    "    \"years_experience\": \"number\",\n",
    "    \"tech_skills\": [\"list of technologies/languages found\"],\n",
    "    \"education_level\": \"string (e.g., 'Bachelor\\'s', 'Master\\'s', 'PhD', 'None mentioned')\",\n",
    "    \"evidence\": \"string - quotes from resume supporting years_experience\"\n",
    "}\n",
    "\n",
    "# Extract features for all candidates\n",
    "candidate_features = []\n",
    "\n",
    "for idx, resume in enumerate(resume_samples):\n",
    "    print(f\"Extracting features for candidate {idx+1}/{len(resume_samples)}...\")\n",
    "    \n",
    "    result = structured_llm_call(\n",
    "        api_key=OPENROUTER_API_KEY,\n",
    "        prompt=feature_extraction_prompt,\n",
    "        context_data={\"resume\": resume['Resume_str']},\n",
    "        output_schema=feature_schema,\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    features = result['result']\n",
    "    features['candidate_id'] = resume['ID']\n",
    "    candidate_features.append(features)\n",
    "\n",
    "display(pd.DataFrame(candidate_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Understanding the Tool Registry\n",
    "\n",
    "Before building the agent, let's examine what tools are available.\n",
    "\n",
    "Each tool has:\n",
    "- A **function** (Python code to execute)\n",
    "- A **description** (what it does)\n",
    "- **parameters** (what inputs it needs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display tool registry\n",
    "print(\"üîß AVAILABLE TOOLS\\n\" + \"=\"*70)\n",
    "\n",
    "for tool_name, tool_info in TOOL_REGISTRY.items():\n",
    "    print(f\"\\nüìå {tool_name}\")\n",
    "    print(f\"   Description: {tool_info['description']}\")\n",
    "    print(f\"   Parameters:\")\n",
    "    for param, desc in tool_info['parameters'].items():\n",
    "        print(f\"      ‚Ä¢ {param}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build the Agent Decision Function\n",
    "\n",
    "The agent needs to:\n",
    "1. Observe the candidate's features and previous actions\n",
    "2. Decide which tool to call next (or if done)\n",
    "3. Provide parameters for that tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_decide_action(\n",
    "    api_key: str,\n",
    "    candidate_id: str,\n",
    "    features: dict,\n",
    "    job_requirements: str,\n",
    "    action_history: list,\n",
    "    tool_registry: dict,\n",
    "    temperature: float,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Agent decides which tool to call next based on candidate features and history.\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'tool', 'parameters', 'reasoning'\n",
    "    \"\"\"\n",
    "    # Build tool descriptions for the agent\n",
    "    tools_desc = \"\\n\".join([\n",
    "        f\"- {name}: {info['description']}\\n  Parameters: {json.dumps(info['parameters'], indent=4)}\"\n",
    "        for name, info in tool_registry.items()\n",
    "    ])\n",
    "    \n",
    "    # Build action history string\n",
    "    history_str = \"\\n\".join([\n",
    "        f\"Turn {i+1}: Called '{action['tool']}' -> {action['result']['message']}\"\n",
    "        for i, action in enumerate(action_history)\n",
    "    ]) if action_history else \"No previous actions\"\n",
    "    \n",
    "    decision_prompt = f\"\"\"\n",
    "You are a hiring automation agent. Your job is to route job applications appropriately.\n",
    "\n",
    "CANDIDATE FEATURES:\n",
    "- ID: {candidate_id}\n",
    "- Years of experience: {features.get('years_experience', 'unknown')}\n",
    "- Tech skills: {', '.join(features.get('tech_skills', []))}\n",
    "- Education: {features.get('education_level', 'unknown')}\n",
    "\n",
    "JOB REQUIREMENTS:\n",
    "- 5-10 years experience required\n",
    "- Technologies: .NET, C#, JavaScript, SQL, AWS\n",
    "\n",
    "ACTION HISTORY:\n",
    "{history_str}\n",
    "\n",
    "AVAILABLE TOOLS:\n",
    "{tools_desc}\n",
    "\n",
    "RULES:\n",
    "1. Strong candidates (5+ years, good tech match) ‚Üí schedule_technical_assessment\n",
    "2. Borderline candidates ‚Üí flag_for_manual_review or request_additional_info\n",
    "3. Weak candidates (< 3 years, poor match) ‚Üí reject_application\n",
    "4. After scheduling assessment ‚Üí send_email with appropriate template\n",
    "5. When all necessary actions taken ‚Üí call 'done'\n",
    "\n",
    "Decide the NEXT action to take. Consider what's already been done.\n",
    "\"\"\"\n",
    "    \n",
    "    decision_schema = {\n",
    "        \"tool\": \"string - name of tool to call (must be from available tools)\",\n",
    "        \"parameters\": \"object - parameters for the tool (must match tool's parameter schema)\",\n",
    "        \"reasoning\": \"string - explanation of why this action is appropriate\"\n",
    "    }\n",
    "    \n",
    "    result = structured_llm_call(\n",
    "        api_key=api_key,\n",
    "        prompt=decision_prompt,\n",
    "        context_data={},\n",
    "        output_schema=decision_schema,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return result['result'], result['usage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build the Agent Loop\n",
    "\n",
    "Now we implement the core agent loop:\n",
    "- **Observe**: Current state and history\n",
    "- **Think**: Decide next action (call LLM)\n",
    "- **Act**: Execute the tool\n",
    "- **Repeat**: Until 'done' or max turns reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_loop(\n",
    "    api_key: str,\n",
    "    candidate_id: str,\n",
    "    features: dict,\n",
    "    job_requirements: str,\n",
    "    tool_registry: dict,\n",
    "    temperature: float,\n",
    "    max_turns: int = 5,\n",
    "    verbose: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Run the agent loop for a single candidate.\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'actions' (list of all actions taken) and 'summary' (final state)\n",
    "    \"\"\"\n",
    "    action_history = []\n",
    "    total_tokens = 0\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Processing Candidate {candidate_id}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Extracted Features:\")\n",
    "        print(f\"  ‚Ä¢ Years experience: {features.get('years_experience', 'unknown')}\")\n",
    "        print(f\"  ‚Ä¢ Tech skills: {', '.join(features.get('tech_skills', []))[:80]}...\")\n",
    "        print(f\"  ‚Ä¢ Education: {features.get('education_level', 'unknown')}\")\n",
    "    \n",
    "    for turn in range(1, max_turns + 1):\n",
    "        if verbose:\n",
    "            print(f\"\\nü§î Agent Decision (Turn {turn}):\")\n",
    "        \n",
    "        # Agent decides next action\n",
    "        decision, usage = agent_decide_action(\n",
    "            api_key=api_key,\n",
    "            candidate_id=candidate_id,\n",
    "            features=features,\n",
    "            job_requirements=job_requirements,\n",
    "            action_history=action_history,\n",
    "            tool_registry=tool_registry,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        total_tokens += usage.get('total_tokens', 0)\n",
    "        \n",
    "        tool_name = decision.get('tool')\n",
    "        params = decision.get('parameters', {})\n",
    "        reasoning = decision.get('reasoning', '')\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  ‚îú‚îÄ Tool: {tool_name}\")\n",
    "            print(f\"  ‚îú‚îÄ Reasoning: {reasoning}\")\n",
    "            print(f\"  ‚îî‚îÄ Parameters: {json.dumps(params, indent=6)}\")\n",
    "        \n",
    "        # Validate tool exists\n",
    "        if tool_name not in tool_registry:\n",
    "            if verbose:\n",
    "                print(f\"  ‚ùå Error: Tool '{tool_name}' not found in registry\")\n",
    "            break\n",
    "        \n",
    "        # Execute tool\n",
    "        tool_function = tool_registry[tool_name]['function']\n",
    "        try:\n",
    "            result = tool_function(**params)\n",
    "            if verbose:\n",
    "                print(f\"\\n  ‚úì Tool Result: {result['message']}\")\n",
    "        except Exception as e:\n",
    "            result = {\"status\": \"error\", \"message\": str(e)}\n",
    "            if verbose:\n",
    "                print(f\"\\n  ‚ùå Tool Error: {e}\")\n",
    "        \n",
    "        # Log action\n",
    "        action_history.append({\n",
    "            'turn': turn,\n",
    "            'tool': tool_name,\n",
    "            'parameters': params,\n",
    "            'reasoning': reasoning,\n",
    "            'result': result,\n",
    "            'tokens_used': usage.get('total_tokens', 0)\n",
    "        })\n",
    "        \n",
    "        # Check if done\n",
    "        if tool_name == 'done' or result.get('final', False):\n",
    "            if verbose:\n",
    "                print(f\"\\n‚úÖ Complete - {turn} turns, {total_tokens:,} tokens used\")\n",
    "            break\n",
    "    \n",
    "    # Determine final outcome\n",
    "    final_actions = [a['tool'] for a in action_history]\n",
    "    if 'schedule_technical_assessment' in final_actions:\n",
    "        outcome = 'PROCEED_TO_INTERVIEW'\n",
    "    elif 'reject_application' in final_actions:\n",
    "        outcome = 'REJECTED'\n",
    "    elif 'flag_for_manual_review' in final_actions:\n",
    "        outcome = 'MANUAL_REVIEW'\n",
    "    else:\n",
    "        outcome = 'IN_PROGRESS'\n",
    "    \n",
    "    return {\n",
    "        'actions': action_history,\n",
    "        'summary': {\n",
    "            'candidate_id': candidate_id,\n",
    "            'years_experience': features.get('years_experience'),\n",
    "            'tech_skills_count': len(features.get('tech_skills', [])),\n",
    "            'total_turns': len(action_history),\n",
    "            'total_tokens': total_tokens,\n",
    "            'final_outcome': outcome,\n",
    "            'actions_taken': ', '.join(final_actions)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run the Agent on Sample Candidates\n",
    "\n",
    "Now let's run our agent on the 3 sampled candidates and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run agent on all candidates\n",
    "all_actions = []\n",
    "all_summaries = []\n",
    "\n",
    "for features in candidate_features:\n",
    "    result = agent_loop(\n",
    "        api_key=OPENROUTER_API_KEY,\n",
    "        candidate_id=features['candidate_id'],\n",
    "        features=features,\n",
    "        job_requirements=job_req,\n",
    "        tool_registry=TOOL_REGISTRY,\n",
    "        temperature=0.2,\n",
    "        max_turns=5,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Collect results\n",
    "    for action in result['actions']:\n",
    "        action['candidate_id'] = features['candidate_id']\n",
    "        all_actions.append(action)\n",
    "    \n",
    "    all_summaries.append(result['summary'])\n",
    "\n",
    "print(f\"\\n\\n{'='*70}\")\n",
    "print(\"‚úì All candidates processed\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Results with DataFrames\n",
    "\n",
    "Now let's create DataFrames to analyze the agent's decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create action log DataFrame\n",
    "action_log_df = pd.DataFrame(all_actions)\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame(all_summaries)\n",
    "\n",
    "print(\"\\nüìä ACTION LOG (all tool calls):\")\n",
    "print(\"=\"*70)\n",
    "display(action_log_df[['candidate_id', 'turn', 'tool', 'reasoning', 'tokens_used']])\n",
    "\n",
    "print(\"\\n\\nüìä SUMMARY (final outcomes):\")\n",
    "print(\"=\"*70)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìà SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTotal candidates processed: {len(summary_df)}\")\n",
    "print(f\"\\nOutcomes:\")\n",
    "for outcome, count in summary_df['final_outcome'].value_counts().items():\n",
    "    print(f\"  ‚Ä¢ {outcome}: {count}\")\n",
    "\n",
    "print(f\"\\nAgent Efficiency:\")\n",
    "print(f\"  ‚Ä¢ Average turns per candidate: {summary_df['total_turns'].mean():.1f}\")\n",
    "print(f\"  ‚Ä¢ Total tokens used: {summary_df['total_tokens'].sum():,}\")\n",
    "print(f\"  ‚Ä¢ Average tokens per candidate: {summary_df['total_tokens'].mean():.0f}\")\n",
    "\n",
    "print(f\"\\nMost Common Tools:\")\n",
    "tool_counts = action_log_df['tool'].value_counts()\n",
    "for tool, count in tool_counts.items():\n",
    "    print(f\"  ‚Ä¢ {tool}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "## Task #0: Run everything\n",
    "\n",
    "Do you agree with the results for the 3 candidates\n",
    "\n",
    "## Task #1: Cost Analysis\n",
    "\n",
    "You have completed the task for 3 candidates. \n",
    "\n",
    "**Questions to answer:**\n",
    "- How much did it cost to process these 3 candidates? (we are using the Claude model)\n",
    "- Based on this sample, how much would it cost to process the entire pile of 130 candidates?\n",
    "\n",
    "**Hints:**\n",
    "- Check the OpenRouter/Anthropic pricing for Claude 3.5 Sonnet\n",
    "- Look at the total tokens used in `summary_df`\n",
    "- Remember: pricing is typically per 1M tokens, split between input and output tokens\n",
    "\n",
    "## Task #2: Temperature Experiment\n",
    "\n",
    "We spoke about model [temperature](https://www.ibm.com/think/topics/llm-temperature).\n",
    "\n",
    "**Questions to explore:**\n",
    "- What happens when we modify the temperature? \n",
    "- It's currently set to 0.2, what happens when we go to 0.5 or 1.0?\n",
    "- Try running the same 3 candidates with different temperatures and compare:\n",
    "  - Do the outcomes change?\n",
    "  - Does the reasoning differ?\n",
    "  - Which temperature gives more consistent results?\n",
    "\n",
    "**Hint:** Modify the `temperature=0.2` parameter in the `agent_loop` call in Step 5\n",
    "\n",
    "## Task #3: Full Sample Run and Cost Verification\n",
    "\n",
    "Now that you understand the costs, run the agent on the **entire dataset** of 130 candidates to verify your cost estimate.\n",
    "\n",
    "**Steps:**\n",
    "1. Extract features for ALL resumes (not just 3)\n",
    "2. Run the agent on all candidates with `verbose=False` to reduce output\n",
    "3. Analyze the results:\n",
    "   - Total cost\n",
    "   - Distribution of outcomes (REJECTED, PROCEED_TO_INTERVIEW, MANUAL_REVIEW)\n",
    "   - Average tokens per candidate\n",
    "   - Most common tool usage patterns\n",
    "4. Compare actual cost to your estimate from Task #1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
